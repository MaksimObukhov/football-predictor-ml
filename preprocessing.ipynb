{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-13T18:13:01.013480200Z",
     "start_time": "2023-11-13T18:12:57.375674700Z"
    }
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Questions before start:\n",
    "We have a bunch of csv files, where each one is divided into categories:\n",
    "1. Country (belgium, england, france, germany, greece, italy, netherlands, portugal, scotland, spain, turkey)\n",
    "2. League (0, 1, 2, 3)\n",
    "3. Season (2000-2001, 2001-2002, ..., 2021-2022)\n",
    "\n",
    "Should we merge all the csv files into one big dataframe? Or should we keep them separate? \n",
    "If we merge them, how do we keep track of the different leagues and seasons?  \n",
    "\n",
    "## Thoughts:\n",
    "We could merge them into one big dataframe, and provide analysis on the whole dataset. \n",
    "In case we need analyse a specific league or season, we can filter the dataframe accordingly.\n",
    "\n",
    "**Before merging**, we should add a column for the league and season.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49f75d7b90073ba2"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# TODO: \n",
    "#  1. try to find in what city match occurred (add as feature), and find related weather data for that city and day (as feature)\n",
    "#  (DONE) 2. check if particular bookmaker appears only in one (or more) country \n",
    "#  (DONE) 3. check if particular bookmaker appears only in one (or more) league\n",
    "#  (DONE) 4. add weekend/weekday as feature (as \"Betting odds for weekend games are collected Friday afternoons, and on Tuesday afternoons for midweek games.\")\n",
    "#  5. add \"number of days since last match\" as feature\n",
    "#  6. check correlations in odds across bookmakers, so that we can drop some columns (probably keep only one bookmaker)\n",
    "#  7. normalization, Use MinMaxScaler for normalization or StandardScaler for standardization, especially for features like betting odds.\n",
    "#  8. convert categorical variables into a format that can be provided to ML algorithms.\n",
    "#  9. Aggregate betting odds across bookmakers. \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-13T19:49:43.261125500Z",
     "start_time": "2023-11-13T19:49:43.239184600Z"
    }
   },
   "id": "d4e85a026f232244"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "import missingno as msno\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5fc890e5dfda728"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# csv_files = sorted(glob(f'data/train/**/*.csv', recursive=True))\n",
    "\n",
    "def read_data_win(folder_path):\n",
    "    df = pd.DataFrame()\n",
    "    for file_path in sorted(glob(f'{folder_path}\\**\\*.csv', recursive=True)):\n",
    "        csv_file_df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Rename HT and AT columns to HomeTeam and AwayTeam\n",
    "        if 'HT' or 'AT' in csv_file_df.columns:\n",
    "            csv_file_df.rename(columns={'HT': 'HomeTeam', 'AT': 'AwayTeam'}, inplace=True)\n",
    "        \n",
    "        # Extract country, league, and season from file path\n",
    "        parts = file_path.split('\\\\')\n",
    "        country = parts[-3]\n",
    "        league = parts[-2]\n",
    "        season = parts[-1].split('.')[0]\n",
    "\n",
    "        # Add country, league, and season as features to the front\n",
    "        csv_file_df.insert(0, 'Country', country)\n",
    "        csv_file_df.insert(1, 'League', league)\n",
    "        csv_file_df.insert(2, 'Season', season)\n",
    "\n",
    "        # Convert date to datetime format and sort by date\n",
    "        csv_file_df['Date'] = pd.to_datetime(csv_file_df['Date'], format='%d/%m/%y', errors='coerce')\n",
    "        if csv_file_df['Date'].isnull().any():\n",
    "            csv_file_df['Date'] = pd.to_datetime(csv_file_df['Date'], format='%d/%m/%Y', errors='coerce')\n",
    "        csv_file_df = csv_file_df.sort_values(by='Date')\n",
    "        \n",
    "        # Determine if the game is on a weekend or weekday\n",
    "        # Weekends are typically Saturday (5) and Sunday (6)\n",
    "        csv_file_df['DayOfWeek'] = csv_file_df['Date'].dt.dayofweek\n",
    "        csv_file_df['Weekend'] = csv_file_df['DayOfWeek'].apply(lambda x: 'Weekend' if x >= 5 else 'Weekday')\n",
    "        \n",
    "        df = pd.concat([df, csv_file_df], ignore_index=True, axis=0, join='outer', sort=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_data_mac(folder_path):\n",
    "    df = pd.DataFrame()\n",
    "    for file_path in sorted(glob(f'{folder_path}/**/*.csv', recursive=True)):\n",
    "        csv_file_df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Rename HT and AT columns to HomeTeam and AwayTeam\n",
    "        if 'HT' or 'AT' in csv_file_df.columns:\n",
    "            csv_file_df.rename(columns={'HT': 'HomeTeam', 'AT': 'AwayTeam'}, inplace=True)\n",
    "        \n",
    "        # Extract country, league, and season from file path\n",
    "        parts = file_path.split('/')\n",
    "        country = parts[-3]\n",
    "        league = parts[-2]\n",
    "        season = parts[-1].split('.')[0]\n",
    "\n",
    "        # Add country, league, and season as features to the front\n",
    "        csv_file_df.insert(0, 'Country', country)\n",
    "        csv_file_df.insert(1, 'League', league)\n",
    "        csv_file_df.insert(2, 'Season', season)\n",
    "\n",
    "        # Convert date to datetime format and sort by date\n",
    "        csv_file_df['Date'] = pd.to_datetime(csv_file_df['Date'], format='%d/%m/%y', errors='coerce')\n",
    "        if csv_file_df['Date'].isnull().any():\n",
    "            csv_file_df['Date'] = pd.to_datetime(csv_file_df['Date'], format='%d/%m/%Y', errors='coerce')\n",
    "        csv_file_df = csv_file_df.sort_values(by='Date')\n",
    "        \n",
    "        # Determine if the game is on a weekend or weekday\n",
    "        # Weekends are typically Saturday (5) and Sunday (6)\n",
    "        csv_file_df['DayOfWeek'] = csv_file_df['Date'].dt.dayofweek\n",
    "        csv_file_df['Weekend'] = csv_file_df['DayOfWeek'].apply(lambda x: 'Weekend' if x >= 5 else 'Weekday')\n",
    "        \n",
    "        df = pd.concat([df, csv_file_df], ignore_index=True, axis=0, join='outer', sort=False)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "602f475e1f878bbb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read all training data\n",
    "#train_df = read_data_mac('data/train')\n",
    "train_df = read_data_win('data\\\\train')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c5ecf07e0442f14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display unique column names and their count\n",
    "unique_columns = train_df.columns.unique()\n",
    "column_count = len(unique_columns)\n",
    "\n",
    "print(\"Unique Column Names:\")\n",
    "print(unique_columns)\n",
    "\n",
    "print(\"\\nNumber of Unique Columns:\", column_count)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce6e4c0d90c11497"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Drop empty columns starting with \"Unnamed\"\n",
    "train_df = train_df.filter(regex='^(?!Unnamed).*$')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4842bed8f2955f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split columns into categories about match (results data), Match Statistics, and betting odds (as in notes.txt)\n",
    "# Rename columns later\n",
    "match_data = {\n",
    "    \"League\": \"League\",\n",
    "    \"Season\": \"Season\",\n",
    "    \"Country\": \"Country\",\n",
    "    \"Div\": \"League_Division\",\n",
    "    \"Date\": \"Match_Date\",\n",
    "    \"Time\": \"Time_of_match_kick_off\",\n",
    "    \"HomeTeam\": \"Home_Team\",\n",
    "    \"AwayTeam\": \"Away_Team\",\n",
    "    \"FTHG\": \"Full_Time_Home_Team_Goals\",\n",
    "    \"FTAG\": \"Full_Time_Away_Team_Goals\",\n",
    "    \"FTR\": \"Full_Time_Result\",\n",
    "    \"HTHG\": \"Half_Time_Home_Team_Goals\",\n",
    "    \"HTAG\": \"Half_Time_Away_Team_Goals\",\n",
    "    \"HTR\": \"Half_Time_Result\"\n",
    "}\n",
    "\n",
    "match_statistics = {\n",
    "    \"Attendance\": \"Crowd_Attendance\",\n",
    "    \"Referee\": \"Match_Referee\",\n",
    "    \"HS\": \"Home_Team_Shots\",\n",
    "    \"AS\": \"Away_Team_Shots\",\n",
    "    \"HST\": \"Home_Team_Shots_on_Target\",\n",
    "    \"AST\": \"Away_Team_Shots_on_Target\",\n",
    "    \"HHW\": \"Home_Team_Hit_Woodwork\",\n",
    "    \"AHW\": \"Away_Team_Hit_Woodwork\",\n",
    "    \"HC\": \"Home_Team_Corners\",\n",
    "    \"AC\": \"Away_Team_Corners\",\n",
    "    \"HF\": \"Home_Team_Fouls_Committed\",\n",
    "    \"AF\": \"Away_Team_Fouls_Committed\",\n",
    "    \"HFKC\": \"Home_Team_Free_Kicks_Conceded\",\n",
    "    \"AFKC\": \"Away_Team_Free_Kicks_Conceded\",\n",
    "    \"HO\": \"Home_Team_Offsides\",\n",
    "    \"AO\": \"Away_Team_Offsides\",\n",
    "    \"HY\": \"Home_Team_Yellow_Cards\",\n",
    "    \"AY\": \"Away_Team_Yellow_Cards\",\n",
    "    \"HR\": \"Home_Team_Red_Cards\",\n",
    "    \"AR\": \"Away_Team_Red_Cards\",\n",
    "    \"HBP\": \"Home_Team_Bookings_Points\",\n",
    "    \"ABP\": \"Away_Team_Bookings_Points\"\n",
    "}\n",
    "\n",
    "betting_odds_1x2_match = {\n",
    "    \"B365H\": \"Bet365_home_win_odds\",\n",
    "    \"B365D\": \"Bet365_draw_odds\",\n",
    "    \"B365A\": \"Bet365_away_win_odds\",\n",
    "    \"BSH\": \"Blue_Square_home_win_odds\",\n",
    "    \"BSD\": \"Blue_Square_draw_odds\",\n",
    "    \"BSA\": \"Blue_Square_away_win_odds\",\n",
    "    \"BWH\": \"Bet&Win_home_win_odds\",\n",
    "    \"BWD\": \"Bet&Win_draw_odds\",\n",
    "    \"BWA\": \"Bet&Win_away_win_odds\",\n",
    "    \"GBH\": \"Gamebookers_home_win_odds\",\n",
    "    \"GBD\": \"Gamebookers_draw_odds\",\n",
    "    \"GBA\": \"Gamebookers_away_win_odds\",\n",
    "    \"IWH\": \"Interwetten_home_win_odds\",\n",
    "    \"IWD\": \"Interwetten_draw_odds\",\n",
    "    \"IWA\": \"Interwetten_away_win_odds\",\n",
    "    \"LBH\": \"Ladbrokes_home_win_odds\",\n",
    "    \"LBD\": \"Ladbrokes_draw_odds\",\n",
    "    \"LBA\": \"Ladbrokes_away_win_odds\",\n",
    "    \"PSH\": \"Pinnacle_home_win_odds\",\n",
    "    \"PSD\": \"Pinnacle_draw_odds\",\n",
    "    \"PSA\": \"Pinnacle_away_win_odds\",\n",
    "    \"SOH\": \"Sporting_Odds_home_win_odds\",\n",
    "    \"SOD\": \"Sporting_Odds_draw_odds\",\n",
    "    \"SOA\": \"Sporting_Odds_away_win_odds\",\n",
    "    \"SBH\": \"Sportingbet_home_win_odds\",\n",
    "    \"SBD\": \"Sportingbet_draw_odds\",\n",
    "    \"SBA\": \"Sportingbet_away_win_odds\",\n",
    "    \"SJH\": \"Stan_James_home_win_odds\",\n",
    "    \"SJD\": \"Stan_James_draw_odds\",\n",
    "    \"SJA\": \"Stan_James_away_win_odds\",\n",
    "    \"SYH\": \"Stanleybet_home_win_odds\",\n",
    "    \"SYD\": \"Stanleybet_draw_odds\",\n",
    "    \"SYA\": \"Stanleybet_away_win_odds\",\n",
    "    \"VCH\": \"VC_Bet_home_win_odds\",\n",
    "    \"VCD\": \"VC_Bet_draw_odds\",\n",
    "    \"VCA\": \"VC_Bet_away_win_odds\",\n",
    "    \"WHH\": \"William_Hill_home_win_odds\",\n",
    "    \"WHD\": \"William_Hill_draw_odds\",\n",
    "    \"WHA\": \"William_Hill_away_win_odds\",\n",
    "    \"Bb1X2\": \"Number_of_BetBrain_bookmakers_used\",\n",
    "    \"BbMxH\": \"Betbrain_maximum_home_win_odds\",\n",
    "    \"BbAvH\": \"Betbrain_average_home_win_odds\",\n",
    "    \"BbMxD\": \"Betbrain_maximum_draw_odds\",\n",
    "    \"BbAvD\": \"Betbrain_average_draw_win_odds\",\n",
    "    \"BbMxA\": \"Betbrain_maximum_away_win_odds\",\n",
    "    \"BbAvA\": \"Betbrain_average_away_win_odds\",\n",
    "    \"MaxH\": \"Market_maximum_home_win_odds\",\n",
    "    \"MaxD\": \"Market_maximum_draw_win_odds\",\n",
    "    \"MaxA\": \"Market_maximum_away_win_odds\",\n",
    "    \"AvgH\": \"Market_average_home_win_odds\",\n",
    "    \"AvgD\": \"Market_average_draw_win_odds\",\n",
    "    \"AvgA\": \"Market_average_away_win_odds\",\n",
    "}\n",
    "\n",
    "betting_odds_total_goals = {\n",
    "    \"BbOU\": \"Number_BetBrain_over_under_2.5_goals_averages_and_maximums\",\n",
    "    \"BbMx>2.5\": \"Betbrain_maximum_over_2.5_goals\",\n",
    "    \"BbAv>2.5\": \"Betbrain_average_over_2.5_goals\",\n",
    "    \"BbMx<2.5\": \"Betbrain_maximum_under_2.5_goals\",\n",
    "    \"BbAv<2.5\": \"Betbrain_average_under_2.5_goals\",\n",
    "    \"GB>2.5\": \"Gamebookers_over_2.5_goals\",\n",
    "    \"GB<2.5\": \"Gamebookers_under_2.5_goals\",\n",
    "    \"B365>2.5\": \"Bet365_over_2.5_goals\",\n",
    "    \"B365<2.5\": \"Bet365_under_2.5_goals\",\n",
    "    \"P>2.5\": \"Pinnacle_over_2.5_goals\",\n",
    "    \"P<2.5\": \"Pinnacle_under_2.5_goals\",\n",
    "    \"Max>2.5\": \"Market_maximum_over_2.5_goals\",\n",
    "    \"Max<2.5\": \"Market_maximum_under_2.5_goals\",\n",
    "    \"Avg>2.5\": \"Market_average_over_2.5_goals\",\n",
    "    \"Avg<2.5\": \"Market_average_under_2.5_goals\",\n",
    "}\n",
    "\n",
    "betting_odds_asian_handicap = {\n",
    "    \"BbAH\": \"Number_BetBrain_handicap_averages_and_maximums\",\n",
    "    \"BbAHh\": \"Betbrain_size_of_handicap_home_team\",\n",
    "    \"AHh\": \"Market_size_handicap_home_team_since_2019/2020\",\n",
    "    \"BbMxAHH\": \"Betbrain_maximum_Asian_handicap_home_team_odds\",\n",
    "    \"BbAvAHH\": \"Betbrain_average_Asian_handicap_home_team_odds\",\n",
    "    \"BbMxAHA\": \"Betbrain_maximum_Asian_handicap_away_team_odds\",\n",
    "    \"BbAvAHA\": \"Betbrain_average_Asian_handicap_away_team_odds\",\n",
    "    \"GBAHH\": \"Gamebookers_Asian_handicap_home_team_odds\",\n",
    "    \"GBAHA\": \"Gamebookers_Asian_handicap_away_team_odds\",\n",
    "    \"GBAH\": \"Gamebookers_size_of_handicap_home_team\",\n",
    "    \"LBAHH\": \"Ladbrokes_Asian_handicap_home_team_odds\",\n",
    "    \"LBAHA\": \"Ladbrokes_Asian_handicap_away_team_odds\",\n",
    "    \"LBAH\": \"Ladbrokes_size_of_handicap_home_team\",\n",
    "    \"B365AHH\": \"Bet365_Asian_handicap_home_team_odds\",\n",
    "    \"B365AHA\": \"Bet365_Asian_handicap_away_team_odds\",\n",
    "    \"B365AH\": \"Bet365_size_of_handicap_home_team\",\n",
    "    \"PAHH\": \"Pinnacle_Asian_handicap_home_team_odds\",\n",
    "    \"PAHA\": \"Pinnacle_Asian_handicap_away_team_odds\",\n",
    "    \"MaxAHH\": \"Market_maximum_Asian_handicap_home_team_odds\",\n",
    "    \"MaxAHA\": \"Market_maximum_Asian_handicap_away_team_odds\",\n",
    "    \"AvgAHH\": \"Market_average_Asian_handicap_home_team_odds\",\n",
    "    \"AvgAHA\": \"Market_average_Asian_handicap_away_team_odds\",\n",
    "}\n",
    "\n",
    "closing_odds = {\n",
    "    'AHCh': 'Market_size_handicap_home_team_since_2019/2020_close',\n",
    "    'AvgC<2.5': 'Average_under_2.5_goals_close',\n",
    "    'AvgC>2.5': 'Average_over_2.5_goals_close',\n",
    "    'AvgCA': 'Away_win_odds_average_close',\n",
    "    'AvgCAHA': 'Asian_handicap_away_team_odds_average_close',\n",
    "    'AvgCAHH': 'Asian_handicap_home_team_odds_average_close',\n",
    "    'AvgCD': 'Draw_odds_average_close',\n",
    "    'AvgCH': 'Home_win_odds_average_close',\n",
    "    'B365C<2.5': 'Bet365_under_2.5_goals_close',\n",
    "    'B365C>2.5': 'Bet365_over_2.5_goals_close',\n",
    "    'B365CA': 'Bet365_away_win_odds_close',\n",
    "    'B365CAHA': 'Bet365_Asian_handicap_away_team_odds_close',\n",
    "    'B365CAHH': 'Bet365_Asian_handicap_home_team_odds_close',\n",
    "    'B365CD': 'Bet365_draw_odds_close',\n",
    "    'B365CH': 'Bet365_home_win_odds_close',\n",
    "    'BWCA': 'Bet&Win_away_win_odds_close',\n",
    "    'BWCD': 'Bet&Win_draw_odds_close',\n",
    "    'BWCH': 'Bet&Win_home_win_odds_close',\n",
    "    'IWCA': 'Interwetten_away_win_odds_close',\n",
    "    'IWCD': 'Interwetten_draw_odds_close',\n",
    "    'IWCH': 'Interwetten_home_win_odds_close',\n",
    "    'MaxC<2.5': 'Market_maximum_under_2.5_goals_close',\n",
    "    'MaxC>2.5': 'Market_maximum_over_2.5_goals_close',\n",
    "    'MaxCA': 'Market_maximum_away_win_odds_close',\n",
    "    'MaxCAHA': 'Market_maximum_Asian_handicap_away_team_odds_close',\n",
    "    'MaxCAHH': 'Market_maximum_Asian_handicap_home_team_odds_close',\n",
    "    'MaxCD': 'Market_maximum_draw_odds_close',\n",
    "    'MaxCH': 'Market_maximum_home_win_odds_close',\n",
    "    'PC<2.5': 'Pinnacle_under_2.5_goals_close',\n",
    "    'PC>2.5': 'Pinnacle_over_2.5_goals_close',\n",
    "    'PCAHA': 'Pinnacle_Asian_handicap_away_team_odds_close',\n",
    "    'PCAHH': 'Pinnacle_Asian_handicap_home_team_odds_close',\n",
    "    'PSCA': 'Pinnacle_away_win_odds_close',\n",
    "    'PSCD': 'Pinnacle_draw_odds_close',\n",
    "    'PSCH': 'Pinnacle_home_win_odds_close',\n",
    "    'VCCA': 'VC_Bet_away_win_odds_close',\n",
    "    'VCCD': 'VC_Bet_draw_odds_close',\n",
    "    'VCCH': 'VC_Bet_home_win_odds_close',\n",
    "    'WHCA': 'William_Hill_away_win_odds_close',\n",
    "    'WHCD': 'William_Hill_draw_odds_close',\n",
    "    'WHCH': 'William_Hill_home_win_odds_close',\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c171ae6717ada69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Number of columns in each category\n",
    "# Combine all sets\n",
    "col_dicts = [\n",
    "    betting_odds_asian_handicap,\n",
    "    betting_odds_total_goals,\n",
    "    betting_odds_1x2_match,\n",
    "    match_statistics,\n",
    "    match_data,\n",
    "    closing_odds\n",
    "]\n",
    "\n",
    "# Calculate the total number of columns in dictionaries\n",
    "num_col = sum(map(len, col_dicts))\n",
    "\n",
    "print(f\"Number of columns in train_df: {len(train_df.columns)}\")\n",
    "print(f\"Number of documented columns: {num_col}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d31529904dcd4796"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combine all dictionary keys into a single set\n",
    "col_dicts_keys = set().union(\n",
    "    betting_odds_asian_handicap.keys(),\n",
    "    betting_odds_total_goals.keys(),\n",
    "    betting_odds_1x2_match.keys(),\n",
    "    match_statistics.keys(),\n",
    "    match_data.keys(),\n",
    "    closing_odds.keys()\n",
    ")\n",
    "\n",
    "# Get the columns in train_df that are not in the combined set of keys\n",
    "extra_columns = set(train_df.columns) - col_dicts_keys\n",
    "\n",
    "# Display the extra columns\n",
    "print(\"Columns not present in dictionaries:\")\n",
    "for column in extra_columns:\n",
    "    print(column)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18ff8a78bf28489e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Maybe we should drop them, as we don't know what they are. (except Weekend and DayOfWeek)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f59ad19b9df84a58"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Thought: each bookmaker might be assigned to one country, so we can add a column for the country of the bookmaker"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a7645766f0f8538"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rename columns in train_df according to the dictionaries\n",
    "for col_dict in col_dicts:\n",
    "    train_df.rename(columns=col_dict, inplace=True)\n",
    "    \n",
    "# Identify duplicate columns\n",
    "duplicate_columns = train_df.columns[train_df.columns.duplicated()]\n",
    "\n",
    "# Print the duplicate columns\n",
    "print(\"Duplicate Columns:\", duplicate_columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e78f53150840291"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2. check if particular bookmaker appears only in one (or more) country\n",
    "bookmakers = ['Bet365', \n",
    "              'Blue_Square', \n",
    "              'Bet&Win', \n",
    "              'Gamebookers', \n",
    "              'Interwetten',\n",
    "              'Ladbrokes', \n",
    "              'Pinnacle', \n",
    "              'Sporting_Odds', \n",
    "              'Sportingbet', \n",
    "              'Stan_James',\n",
    "              'Stanleybet', \n",
    "              'VC_Bet', \n",
    "              'William_Hill']\n",
    "\n",
    "df_test = train_df.copy()\n",
    "# Create indicator columns for each bookmaker\n",
    "for bookmaker in bookmakers:\n",
    "    indicator_column = f'{bookmaker}_indicator'\n",
    "    columns_to_check = [col for col in df_test.columns if bookmaker in col]\n",
    "    df_test[indicator_column] = df_test[columns_to_check].any(axis=1).astype(int)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4591caab6a15825d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# List of indicator columns (replace this with your actual indicator columns)\n",
    "indicator_columns = ['Bet365_indicator', 'Blue_Square_indicator', 'Bet&Win_indicator', 'Gamebookers_indicator',\n",
    "                     'Interwetten_indicator', 'Ladbrokes_indicator', 'Pinnacle_indicator', 'Sporting_Odds_indicator',\n",
    "                     'Sportingbet_indicator', 'Stan_James_indicator', 'Stanleybet_indicator', 'VC_Bet_indicator',\n",
    "                     'William_Hill_indicator']\n",
    "\n",
    "# Group by 'Country' and count the occurrences of 1 for each bookmaker\n",
    "grouped_df = df_test.groupby('Country')[indicator_columns].sum().reset_index()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3174d57bade89cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot a bar chart for each country\n",
    "for index, row in grouped_df.iterrows():\n",
    "    country_name = row['Country']\n",
    "    bookmaker_counts = row[indicator_columns].astype(int)\n",
    "    bookmaker_name = [bkmkr.split('_indicator')[0] for bkmkr in indicator_columns]\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.bar(bookmaker_name, bookmaker_counts, color='skyblue')\n",
    "    plt.title(f'Bookmaker Counts in {country_name}')\n",
    "    plt.xlabel('Bookmaker')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6489b290e9243e4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### There is no significant difference in bet distribution between the bookmakers per country."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffb8f89afda19713"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Group by 'League' and count the occurrences of 1 for each bookmaker\n",
    "grouped_df = df_test.groupby('League')[indicator_columns].sum().reset_index()\n",
    "\n",
    "# Plot a bar chart for each league\n",
    "for index, row in grouped_df.iterrows():\n",
    "    league_name = row['League']\n",
    "    bookmaker_counts = row[indicator_columns].astype(int)\n",
    "    bookmaker_name = [bkmkr.split('_indicator')[0] for bkmkr in indicator_columns]\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.bar(bookmaker_name, bookmaker_counts, color='skyblue')\n",
    "    plt.title(f'Bookmaker Counts in {league_name} League')\n",
    "    plt.xlabel('Bookmaker')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e59209f32b5a774d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### There is no significant difference in bet distribution between the bookmakers per league."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1c88fa42c3a6a44"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NAs treatment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6303e7d179f17f11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c65486380e460b29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ac579711c33206"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dropping rows with missing values of our target variable and main indicators as long as they have less then 1% missing data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "100f97f2ba0a7ca5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove rows \n",
    "train_df = train_df.dropna(subset=['Full_Time_Result', 'Home_Team', 'Away_Team', 'Full_Time_Home_Team_Goals', 'Full_Time_Away_Team_Goals', 'Half_Time_Home_Team_Goals', 'Half_Time_Away_Team_Goals', 'Half_Time_Result', 'League_Division'])\n",
    "\n",
    "# check how many rows we have left after this operation\n",
    "remaining_rows = train_df.shape[0]\n",
    "print(remaining_rows)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b463e8c75e6f95d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df_old = train_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb563dad31c83353"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imputing missing match statistics values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7954a0e08edfec20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Identify the columns for match statistics\n",
    "match_stats_columns = [\n",
    "    'Home_Team_Shots', 'Away_Team_Shots', \n",
    "    'Home_Team_Shots_on_Target', 'Away_Team_Shots_on_Target', \n",
    "    'Home_Team_Corners', 'Away_Team_Corners', \n",
    "    'Home_Team_Yellow_Cards', 'Away_Team_Yellow_Cards',\n",
    "    'Home_Team_Red_Cards', 'Away_Team_Red_Cards',\n",
    "    'Home_Team_Fouls_Committed', 'Away_Team_Fouls_Committed',\n",
    "    # Add any other relevant columns here\n",
    "]\n",
    "train_df[match_stats_columns].describe()\n",
    "\n",
    "#for column in match_stats_columns:\n",
    "    #plt.figure(figsize=(10, 4))\n",
    "    #sns.histplot(train_df[column], kde=True)\n",
    "    #plt.title(f'Distribution of {column}')\n",
    "    #plt.show()'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1185ab2f1ee61fb7"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "924aefcb1505a389"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b5aa6db8546f4f30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking if data is missing on random or not"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b79869e333f11a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize the missingness pattern using missingno\n",
    "msno.matrix(train_df)\n",
    "plt.show()\n",
    "\n",
    "msno.heatmap(train_df)\n",
    "plt.show()\n",
    "\n",
    "# Create a missingness indicator DataFrame\n",
    "missing_indicator = train_df.isna()\n",
    "\n",
    "# Heatmap of missingness correlation using standard correlation\n",
    "sns.heatmap(missing_indicator.corr(), cmap='viridis', annot=True)\n",
    "plt.title(\"Correlation Heatmap of Missing Data\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "131c79d12c4135e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Complex Impputation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eda8882a0527548f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a subset DataFrame with only the match statistics columns\n",
    "subset_df = train_df[match_stats_columns]\n",
    "\n",
    "# Initialize the IterativeImputer\n",
    "iterative_imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "# Fit the imputer on your subset and transform it\n",
    "subset_df_imputed = iterative_imputer.fit_transform(subset_df)\n",
    "\n",
    "# Create a DataFrame from the imputed subset data\n",
    "subset_df_imputed = pd.DataFrame(subset_df_imputed, columns=subset_df.columns)\n",
    "\n",
    "# Check the result\n",
    "print(pd.DataFrame(subset_df_imputed, columns=match_stats_columns).isna().sum())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32f1716048a27709"
  },
  {
   "cell_type": "markdown",
   "source": [
    "started at 15 13"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44d462738b8bae7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a subset DataFrame with only the match statistics columns\n",
    "subset_df = train_df[match_stats_columns]\n",
    "\n",
    "# Initialize the IterativeImputer with RandomForestRegressor as the estimator\n",
    "rf_imputer = IterativeImputer(estimator=RandomForestRegressor(n_estimators=10), max_iter=10, random_state=0)\n",
    "\n",
    "# Fit the imputer on your subset and transform it\n",
    "subset_df_imputed_rf = rf_imputer.fit_transform(subset_df)\n",
    "\n",
    "# Create a DataFrame from the imputed subset data\n",
    "subset_df_imputed_rf = pd.DataFrame(subset_df_imputed_rf, columns=subset_df.columns)\n",
    "\n",
    "# Check the result\n",
    "print(subset_df_imputed_rf.isna().sum())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f4c87e38f8ad613"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Summary statistics for the original data\n",
    "train_df_old[match_stats_columns].describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58ce350dc32da3c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Summary statistics for the first imputation\n",
    "subset_df_imputed.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82e7863dbd1acf57"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Summary statistics for the RandomForest imputation\n",
    "subset_df_imputed_rf.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "393487796e161e4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Summary statistics for the original data\n",
    "original_stats = train_df_old[match_stats_columns].describe()\n",
    "# Summary statistics for the first imputation\n",
    "first_impute_stats = subset_df_imputed.describe()\n",
    "# Summary statistics for the RandomForest imputation\n",
    "rf_impute_stats = subset_df_imputed_rf.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "924e7f8e2a22146a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Histograms for each variable\n",
    "for column in match_stats_columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(train_df_old[column].dropna(), alpha=0.5, label='Original')\n",
    "    plt.hist(subset_df_imputed[column], alpha=0.5, label='First Imputation')\n",
    "    plt.hist(subset_df_imputed_rf[column], alpha=0.5, label='RF Imputation')\n",
    "    plt.title(f'Distribution for {column}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15d9f23da7093d2b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mean imputation\n",
    "'''\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "columns_for_mean_imputation = ['Home_Team_Shots', 'Away_Team_Shots', \n",
    "                               'Home_Team_Shots_on_Target', 'Away_Team_Shots_on_Target',\n",
    "                               'Home_Team_Corners', 'Away_Team_Corners']\n",
    "\n",
    "train_df[columns_for_mean_imputation] = mean_imputer.fit_transform(train_df[columns_for_mean_imputation])\n",
    "\n",
    "# Median imputation\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "columns_for_median_imputation = ['Home_Team_Yellow_Cards', 'Away_Team_Yellow_Cards',\n",
    "                                 'Home_Team_Red_Cards', 'Away_Team_Red_Cards',\n",
    "                                 'Home_Team_Fouls_Committed', 'Away_Team_Fouls_Committed']\n",
    "\n",
    "train_df[columns_for_median_imputation] = median_imputer.fit_transform(train_df[columns_for_median_imputation])\n",
    "\n",
    "# Check the result\n",
    "print(train_df[match_stats_columns].isna().sum())'''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59f2a1c4b119ab13"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove columns with excessive missingness"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11a9cbdcd4e2884f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''# Define a threshold for the maximum allowed proportion of missing values\n",
    "threshold = 0.98\n",
    "\n",
    "# Calculate the proportion of missing values for each column\n",
    "missing_proportion = train_df.isna().sum() / len(train_df)\n",
    "\n",
    "# Identify columns that have missing values above the threshold\n",
    "columns_to_drop = missing_proportion[missing_proportion > threshold].index.tolist()\n",
    "\n",
    "# Drop these columns from the DataFrame\n",
    "train_df = train_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display the columns that have been dropped\n",
    "print(f\"Columns dropped: {columns_to_drop}\")'''\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a679dd5a968b3f0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bookmakers odds corelation\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9279027e83cbac5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Selecting home win odds from different bookmakers as an example\n",
    "home_win_odds_columns = [\n",
    "    \"Bet365_home_win_odds\", \"Blue_Square_home_win_odds\", \"Bet&Win_home_win_odds\",\n",
    "    \"Gamebookers_home_win_odds\", \"Interwetten_home_win_odds\", \"Ladbrokes_home_win_odds\",\n",
    "    \"Pinnacle_home_win_odds\", \"Sporting_Odds_home_win_odds\", \"Sportingbet_home_win_odds\",\n",
    "    \"Stan_James_home_win_odds\", \"Stanleybet_home_win_odds\", \"VC_Bet_home_win_odds\",\n",
    "    \"William_Hill_home_win_odds\"\n",
    "]\n",
    "\n",
    "# Compute the correlation matrix for home win odds\n",
    "correlation_matrix_home_win = train_df[home_win_odds_columns].corr()\n",
    "\n",
    "# Generate a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix_home_win, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix for Home Win Odds')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6aebd6e98e45883"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Selecting draw odds from different bookmakers\n",
    "draw_odds_columns = [\n",
    "    \"Bet365_draw_odds\", \"Blue_Square_draw_odds\", \"Bet&Win_draw_odds\",\n",
    "    \"Gamebookers_draw_odds\", \"Interwetten_draw_odds\", \"Ladbrokes_draw_odds\",\n",
    "    \"Pinnacle_draw_odds\", \"Sporting_Odds_draw_odds\", \"Sportingbet_draw_odds\",\n",
    "    \"Stan_James_draw_odds\", \"Stanleybet_draw_odds\", \"VC_Bet_draw_odds\",\n",
    "    \"William_Hill_draw_odds\"\n",
    "]\n",
    "\n",
    "# Compute the correlation matrix for draw odds\n",
    "correlation_matrix_draw = train_df[draw_odds_columns].corr()\n",
    "\n",
    "# Generate a heatmap of the correlation matrix for draw odds\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix_draw, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix for Draw Odds')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9f11aa7f1ab88fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e73f6ced8b45d31e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
