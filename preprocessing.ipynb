{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-10T16:16:47.328280Z",
     "start_time": "2023-11-10T16:16:45.641382Z"
    }
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Questions before start:\n",
    "We have a bunch of csv files, where each one is divided into categories:\n",
    "1. Country (belgium, england, france, germany, greece, italy, netherlands, portugal, scotland, spain, turkey)\n",
    "2. League (0, 1, 2, 3)\n",
    "3. Season (2000-2001, 2001-2002, ..., 2021-2022)\n",
    "\n",
    "Should we merge all the csv files into one big dataframe? Or should we keep them separate? \n",
    "If we merge them, how do we keep track of the different leagues and seasons?  \n",
    "\n",
    "## Max's thoughts:\n",
    "We could merge them into one big dataframe, and provide analysis on the whole dataset. \n",
    "In case we need analyse a specific league or season, we can filter the dataframe accordingly.\n",
    "\n",
    "**Before merging**, we should add a column for the league and season.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49f75d7b90073ba2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T11:14:20.121161Z",
     "start_time": "2023-11-11T11:14:20.115141Z"
    }
   },
   "id": "a269965b0105148b"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# csv_files = sorted(glob(f'data/train/**/*.csv', recursive=True))\n",
    "\n",
    "def read_data(folder_path):\n",
    "    df = pd.DataFrame()\n",
    "    for file_path in sorted(glob(f'{folder_path}/**/*.csv', recursive=True)):\n",
    "        csv_file = pd.read_csv(file_path)\n",
    "        # TODO: turn into data format -> sort by date -> add season feature from csv name-> concat\n",
    "        \n",
    "        # Extract country, league, and season from file path\n",
    "        parts = file_path.split('/')\n",
    "        country = parts[-3]\n",
    "        league = parts[-2]\n",
    "        season = parts[-1].split('.')[0]\n",
    "\n",
    "        # Add country, league, and season as features\n",
    "        csv_file['Country'] = country\n",
    "        csv_file['League'] = league\n",
    "        csv_file['Season'] = season\n",
    "\n",
    "        # Convert date to datetime format and sort by date\n",
    "        csv_file['Date'] = pd.to_datetime(csv_file['Date'], format='%d/%m/%y', errors='coerce')\n",
    "        csv_file = csv_file.sort_values(by='Date')\n",
    "        \n",
    "        df = pd.concat([df, csv_file], ignore_index=True, axis=0, join='outer', sort=False)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T12:38:56.308440Z",
     "start_time": "2023-11-11T12:38:56.300487Z"
    }
   },
   "id": "62fdfd4e3f168526"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Read all training data\n",
    "train_df = read_data('data/train')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T12:39:39.157410Z",
     "start_time": "2023-11-11T12:39:26.819369Z"
    }
   },
   "id": "92eeb7cbe9be4d4c"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# # Specify the directory where your CSV files are located\n",
    "# csv_files = sorted(glob('data/train/england/0/*.csv'))\n",
    "# \n",
    "# # Create an empty dataframe to store the merged data\n",
    "# merged_df = pd.DataFrame()\n",
    "# \n",
    "# # Iterate through each CSV file\n",
    "# for file in csv_files:\n",
    "#     # Read each CSV file into a temporary dataframe\n",
    "#     temp_df = pd.read_csv(file)\n",
    "# \n",
    "#     # Merge the dataframes based on unique columns\n",
    "#     test_df = pd.concat([test_df, temp_df], axis=0, join='outer', sort=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T21:19:22.371787Z",
     "start_time": "2023-11-10T21:19:22.264056Z"
    }
   },
   "id": "3ac551e10c8f2cc8"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Column Names:\n",
      "Index(['Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG',\n",
      "       'HTAG', 'HTR',\n",
      "       ...\n",
      "       'SOD', 'SOA', 'LBAHH', 'LBAHA', 'LBAH', 'LB', 'LB.1', 'LB.2', 'HT',\n",
      "       'AT'],\n",
      "      dtype='object', length=171)\n",
      "\n",
      "Number of Unique Columns: 171\n"
     ]
    }
   ],
   "source": [
    "# Display unique column names and their count\n",
    "unique_columns = train_df.columns.unique()\n",
    "column_count = len(unique_columns)\n",
    "\n",
    "print(\"Unique Column Names:\")\n",
    "print(unique_columns)\n",
    "\n",
    "print(\"\\nNumber of Unique Columns:\", column_count)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T12:39:20.323386Z",
     "start_time": "2023-11-11T12:39:20.318581Z"
    }
   },
   "id": "f6e3e41839bae2a"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Drop empty columns starting with \"Unnamed\"\n",
    "train_df = train_df.filter(regex='^(?!Unnamed).*$')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T12:39:54.277590Z",
     "start_time": "2023-11-11T12:39:54.139058Z"
    }
   },
   "id": "26c50362fb19e42d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: split columns into categories about match (results data), Match Statistics, and betting odds (as in notes.txt)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b3a6742ea8b297a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
